* take example of drug which treated illness, three groups given different dosages
* The data looks like this <img width="707" height="404" alt="image" src="https://github.com/user-attachments/assets/189f016f-fbc0-463c-9cc2-096e9dd51276" />

* like linear regression we cannot fit straight line to this <img width="707" height="404" alt="image" src="https://github.com/user-attachments/assets/eefde6d6-a930-4295-a1e6-b08284f9e6b8" />
* But neural network can fit squiggle to the data <img width="707" height="404" alt="image" src="https://github.com/user-attachments/assets/24d17361-3873-4e70-a744-e849a6422b80" />
* Neural network can fit any kind of complecated squiggles
* So Neural netowork consists of nodes, connections between noodes,the numbers along each connection represent parameters values weere estimated when this neural network was fit to data
* <img width="707" height="479" alt="image" src="https://github.com/user-attachments/assets/4f21b565-c795-448a-9469-b294a71e45d1" />

* you can say they are alalogous to slope and intercept in linear regression (these are found using backpropagation)
* <img width="707" height="479" alt="image" src="https://github.com/user-attachments/assets/c9d19991-9ee1-4b80-8a4f-68bd80cd4d25" />

* these identical curves can be reshaped by the parameter values and the add together to get the squiggle to fit the data
* There are many common bent or curved lines that we can choose for a neural network
* This one is softplus <img width="707" height="479" alt="image" src="https://github.com/user-attachments/assets/0cd16228-f590-4034-92d2-942579fc0262" />

* ReLU <img width="707" height="479" alt="image" src="https://github.com/user-attachments/assets/260c7249-6ba2-4cf2-8dc8-1bb92389cde9" />
* Sigmoid <img width="707" height="479" alt="image" src="https://github.com/user-attachments/assets/6e4d797e-2936-412e-8033-6e0ad9047db1" />
* These curves or bent lines are called activation functions
* We have taken example of simple neural network, 



