# ENcoder Only Transformers

* Encoder forms the basis for **BERT**

* It follows following
  * Word Embedding
  * Positional Encoding
  * **Self Attention**
  * <img width="1109" height="592" alt="image" src="https://github.com/user-attachments/assets/7d9c32ae-56ff-4091-9c32-8fe6ee6192ac" />
  * context aware embeddings
  * Context aware embeddings can help cluster similar sentences or even similar documents
  * ENcoder only transformers like BERT that uses only use self attention can create context aware embeddings
  * <img width="1109" height="592" alt="image" src="https://github.com/user-attachments/assets/6bf505a9-651e-4ac6-aae4-1d204c9aa28a" />

  * <img width="1109" height="592" alt="image" src="https://github.com/user-attachments/assets/add369dd-846a-4ec4-bea3-7ecce900553b" />
  * <img width="1109" height="592" alt="image" src="https://github.com/user-attachments/assets/dcd29140-8078-4599-9525-edc2b3f85e36" />
  * <img width="1109" height="592" alt="image" src="https://github.com/user-attachments/assets/26f73dba-5d58-4a3a-be48-63d9f612365a" />
  * <img width="1109" height="592" alt="image" src="https://github.com/user-attachments/assets/c761c747-01ea-4d4a-afca-71625d0640d3" />
  * <img width="1109" height="592" alt="image" src="https://github.com/user-attachments/assets/06a32fcf-bdd2-4f0f-9bc7-1d7edbd02b17" />
  * <img width="1109" height="592" alt="image" src="https://github.com/user-attachments/assets/5880d63b-a357-4dd0-9096-99bcaa6f3186" />

  * <img width="1109" height="592" alt="image" src="https://github.com/user-attachments/assets/af6af98f-8d97-4b05-8816-98dcb46dd9ec" />
  * <img width="1109" height="592" alt="image" src="https://github.com/user-attachments/assets/c5552ef9-b7ac-4dae-a0f5-2a9ad2233eb6" />
  * <img width="1109" height="592" alt="image" src="https://github.com/user-attachments/assets/9b6e0e2c-6383-4ec5-b28e-28dae418af7f" />
  * 








* 
